{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WordToVec tutorial\n",
    "\n",
    "+ Take a 3 layer neural network. (1 input layer + 1 hidden layer + 1 output layer)\n",
    "+ Feed it a word and train it to predict its neighbouring word.\n",
    "+ Remove the last (output layer) and keep the input and hidden layer.\n",
    "+ Now, input a word from within the vocabulary. The output given at the hidden layer is the ‘word embedding’ of the input word.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "corpus_raw = \"He is the king . The king is royal . She is the royal  queen \"\n",
    "corpus = corpus_raw.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for i in corpus.split():\n",
    "    if( i != '.' ):\n",
    "        words.append(i)\n",
    "words = set(words)\n",
    "word2int = {}\n",
    "int2word = {}\n",
    "vocab_size = len(words)\n",
    "\n",
    "for i,word in enumerate(words):\n",
    "    #print(i,word)\n",
    "    word2int[word] = i \n",
    "    int2word[i] = word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(word2int['queen'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "royal\n"
     ]
    }
   ],
   "source": [
    "print(int2word[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['he', 'is', 'the', 'king'], ['the', 'king', 'is', 'royal'], ['she', 'is', 'the', 'royal', 'queen']]\n"
     ]
    }
   ],
   "source": [
    "raw_sentences = corpus.split(\".\")\n",
    "sentences = []\n",
    "for i in raw_sentences:\n",
    "    sentences.append(i.split())\n",
    "print(sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "WINDOW_SZ = 2\n",
    "for i in sentences:\n",
    "    for idx, word in enumerate(i):\n",
    "        for nb_word in i[max(idx - WINDOW_SZ, 0) : min(idx + WINDOW_SZ, len(i)) + 1]:\n",
    "            if (nb_word != word):\n",
    "                data.append([word, nb_word])\n",
    "                #print(\"  \",[word, nb_word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['he', 'is'],\n",
       " ['he', 'the'],\n",
       " ['is', 'he'],\n",
       " ['is', 'the'],\n",
       " ['is', 'king'],\n",
       " ['the', 'he'],\n",
       " ['the', 'is'],\n",
       " ['the', 'king'],\n",
       " ['king', 'is'],\n",
       " ['king', 'the'],\n",
       " ['the', 'king'],\n",
       " ['the', 'is'],\n",
       " ['king', 'the'],\n",
       " ['king', 'is'],\n",
       " ['king', 'royal'],\n",
       " ['is', 'the'],\n",
       " ['is', 'king'],\n",
       " ['is', 'royal'],\n",
       " ['royal', 'king'],\n",
       " ['royal', 'is'],\n",
       " ['she', 'is'],\n",
       " ['she', 'the'],\n",
       " ['is', 'she'],\n",
       " ['is', 'the'],\n",
       " ['is', 'royal'],\n",
       " ['the', 'she'],\n",
       " ['the', 'is'],\n",
       " ['the', 'royal'],\n",
       " ['the', 'queen'],\n",
       " ['royal', 'is'],\n",
       " ['royal', 'the'],\n",
       " ['royal', 'queen'],\n",
       " ['queen', 'the'],\n",
       " ['queen', 'royal']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(data))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34, 7) (34, 7)\n"
     ]
    }
   ],
   "source": [
    "def to_one_hot(data_point_idx, vocab_size):\n",
    "    temp = np.zeros(vocab_size)\n",
    "    temp[data_point_idx] = 1\n",
    "    return temp\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in data:\n",
    "    x_train.append(to_one_hot(word2int[i[0]],vocab_size))\n",
    "    y_train.append(to_one_hot(word2int[i[1]],vocab_size))\n",
    "    \n",
    "x_train = np.asarray(x_train)\n",
    "y_train = np.asarray(y_train)\n",
    "#print(x_train)\n",
    "print(x_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32,shape=[None,vocab_size])\n",
    "y_label = tf.placeholder(tf.float32, shape=[None,vocab_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 5\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([vocab_size,EMBEDDING_DIM]))\n",
    "b1 = tf.Variable(tf.random_normal([EMBEDDING_DIM]))\n",
    "hidden_representation = tf.add(tf.matmul(x,W1),b1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([EMBEDDING_DIM,vocab_size]))\n",
    "b2 = tf.Variable(tf.random_normal([vocab_size]))\n",
    "prediction = tf.nn.softmax(tf.add(tf.matmul(hidden_representation,W2),b2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
