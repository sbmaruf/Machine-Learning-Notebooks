{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np #for matrix \n",
    "import matplotlib.pyplot as plt #for plotting\n",
    "import tensorflow as tf #guru :)\n",
    "import xlrd #for reading excel file\n",
    " \n",
    "DATA_FILE = 'slr05.xls' #input file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Read the xls file using xlrd library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: read in data from the .xls file\n",
    "book = xlrd.open_workbook(DATA_FILE, encoding_override=\"utf-8\")\n",
    "sheet = book.sheet_by_index(0)\n",
    "data = np.asarray([sheet.row_values(i) for i in range(1, sheet.nrows)])\n",
    "n_samples = sheet.nrows - 1\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Create input/output for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 2: create placeholders for input X (number of fire) and label Y (number of thef)\n",
    "X = tf.placeholder(tf.float32, name='X')\n",
    "Y = tf.placeholder(tf.float32, name='Y')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 3: create variables: weights_1, weights_2, bias. All are initialized to 0 \n",
    "w = tf.Variable(0.0)\n",
    "u = tf.Variable(0.0)\n",
    "b = tf.Variable(0.0)\n",
    " \n",
    "Y_predicted = X * X * w + X * u + b ; \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Squared error as cost/loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 5: use the square error as the loss function\n",
    "loss = tf.square(Y - Y_predicted, name='loss')\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with optimizar :: Gradient Descent\n",
    "\n",
    "Learning rate means how slow or how fast the algorithm will try to jump to the solution. \n",
    "<br />Note that, do not make it too small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 6: using gradient descent with learning rate of 0.01 to minimize loss\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1 : Initialize all the variable in the tensorflow Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    # Step 7: initialize the necessary variables, in this case, w and b\n",
    "    sess.run(tf.global_variables_initializer()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2 : Maintain log for tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    # Step 7: initialize the necessary variables, in this case, w and b\n",
    "    sess.run(tf.global_variables_initializer()) \n",
    " \n",
    "    writer = tf.summary.FileWriter('./linear_reg', sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3 : Decide how many epoch you want to train the model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 0.0\n",
      "Epoch 1: 0.0\n",
      "Epoch 2: 0.0\n",
      "Epoch 3: 0.0\n",
      "Epoch 4: 0.0\n",
      "Epoch 5: 0.0\n",
      "Epoch 6: 0.0\n",
      "Epoch 7: 0.0\n",
      "Epoch 8: 0.0\n",
      "Epoch 9: 0.0\n",
      "Epoch 10: 0.0\n",
      "Epoch 11: 0.0\n",
      "Epoch 12: 0.0\n",
      "Epoch 13: 0.0\n",
      "Epoch 14: 0.0\n",
      "Epoch 15: 0.0\n",
      "Epoch 16: 0.0\n",
      "Epoch 17: 0.0\n",
      "Epoch 18: 0.0\n",
      "Epoch 19: 0.0\n",
      "Epoch 20: 0.0\n",
      "Epoch 21: 0.0\n",
      "Epoch 22: 0.0\n",
      "Epoch 23: 0.0\n",
      "Epoch 24: 0.0\n",
      "Epoch 25: 0.0\n",
      "Epoch 26: 0.0\n",
      "Epoch 27: 0.0\n",
      "Epoch 28: 0.0\n",
      "Epoch 29: 0.0\n",
      "Epoch 30: 0.0\n",
      "Epoch 31: 0.0\n",
      "Epoch 32: 0.0\n",
      "Epoch 33: 0.0\n",
      "Epoch 34: 0.0\n",
      "Epoch 35: 0.0\n",
      "Epoch 36: 0.0\n",
      "Epoch 37: 0.0\n",
      "Epoch 38: 0.0\n",
      "Epoch 39: 0.0\n",
      "Epoch 40: 0.0\n",
      "Epoch 41: 0.0\n",
      "Epoch 42: 0.0\n",
      "Epoch 43: 0.0\n",
      "Epoch 44: 0.0\n",
      "Epoch 45: 0.0\n",
      "Epoch 46: 0.0\n",
      "Epoch 47: 0.0\n",
      "Epoch 48: 0.0\n",
      "Epoch 49: 0.0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # Step 7: initialize the necessary variables, in this case, w and b\n",
    "    sess.run(tf.global_variables_initializer()) \n",
    " \n",
    "    writer = tf.summary.FileWriter('./linear_reg', sess.graph)\n",
    "\n",
    "    # Step 8: train the model\n",
    "    for i in range(50): # train the model 50 times\n",
    "        total_loss = 0\n",
    "        \n",
    "        \n",
    "        ### there will be code later steps\n",
    "        \n",
    "        \n",
    "        print('Epoch {0}: {1}'.format(i, total_loss/n_samples))\n",
    " \n",
    "    # close the writer when you're done using it\n",
    "    writer.close() \n",
    "\n",
    "    # Step 9: output the values of w and b\n",
    "    w_value, u_value , b_value = sess.run([w, u , b]) \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step 4 : Run gradient descent manually.\n",
    "\n",
    "* provide the loss function and learning variable to apply gradient over them.\n",
    "* Define a valid range of gradient so that it could not expolde\n",
    "* Assign random value in the cliiped range to the learning variable and feed it to a optimizer.\n",
    "* run the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 939.2386015951633\n",
      "Epoch 1: 3092.237165541876\n",
      "Epoch 2: 6877.785153911227\n",
      "Epoch 3: 12457.279960264763\n",
      "Epoch 4: 15339.539540722788\n",
      "Epoch 5: 16136.505860655081\n",
      "Epoch 6: 16954.870504664523\n",
      "Epoch 7: 17794.618683785557\n",
      "Epoch 8: 17676.920106380112\n",
      "Epoch 9: 17372.622104366885\n",
      "Epoch 10: 17071.04075596506\n",
      "Epoch 11: 16810.637067363707\n",
      "Epoch 12: 16748.67381031831\n",
      "Epoch 13: 16497.286830040404\n",
      "Epoch 14: 16203.64108840273\n",
      "Epoch 15: 16181.751151184431\n",
      "Epoch 16: 15943.795170013993\n",
      "Epoch 17: 15655.277071691995\n",
      "Epoch 18: 15468.812138103467\n",
      "Epoch 19: 15204.237431500467\n",
      "Epoch 20: 15262.508921041735\n",
      "Epoch 21: 15046.993604648991\n",
      "Epoch 22: 14766.974050252078\n",
      "Epoch 23: 14489.667192997544\n",
      "Epoch 24: 14370.56355087375\n",
      "Epoch 25: 14127.563875546357\n",
      "Epoch 26: 13967.681755960664\n",
      "Epoch 27: 13719.995611983446\n",
      "Epoch 28: 13714.25998882563\n",
      "Epoch 29: 13498.438999918024\n",
      "Epoch 30: 13233.749904952467\n",
      "Epoch 31: 13012.448908512506\n",
      "Epoch 32: 12848.793324646285\n",
      "Epoch 33: 13583.99121404191\n",
      "Epoch 34: 13318.379104772848\n",
      "Epoch 35: 13055.481211882972\n",
      "Epoch 36: 12795.299928308776\n",
      "Epoch 37: 12537.759269157032\n",
      "Epoch 38: 12456.10126150242\n",
      "Epoch 39: 12474.24589406872\n",
      "Epoch 40: 12219.818539194852\n",
      "Epoch 41: 12936.802265732062\n",
      "Epoch 42: 12677.788720993769\n",
      "Epoch 43: 12421.486776550611\n",
      "Epoch 44: 12167.901324865896\n",
      "Epoch 45: 11917.033271106216\n",
      "Epoch 46: 11668.553167277681\n",
      "Epoch 47: 12369.07584695589\n",
      "Epoch 48: 12116.00893898663\n",
      "Epoch 49: 11865.65688529043\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # Step 7: initialize the necessary variables, in this case, w and b\n",
    "    sess.run(tf.global_variables_initializer()) \n",
    " \n",
    "    writer = tf.summary.FileWriter('./linear_reg', sess.graph)\n",
    "\n",
    "    # Step 8: train the model\n",
    "    for i in range(50): # train the model 50 times\n",
    "        total_loss = 0\n",
    "        gradients = tf.gradients(loss, [ u , w , b ] )\n",
    "        clipped_gradients, norm = tf.clip_by_global_norm(gradients,5)\n",
    "        apply = optimizer.apply_gradients(zip(clipped_gradients, [u,w,b]))\n",
    "        for x, y in data:    \n",
    "            _, l = sess.run([apply, loss], feed_dict={X: x, Y:y}) \n",
    "            total_loss += l\n",
    "        print('Epoch {0}: {1}'.format(i, total_loss/n_samples)) \n",
    " \n",
    "    # close the writer when you're done using it\n",
    "    writer.close() \n",
    "\n",
    "    # Step 9: output the values of w and b\n",
    "    w_value, u_value , b_value = sess.run([w, u , b]) \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-3ad0f610f3a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# plot the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bo'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Real data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mw_value\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mu_value\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Predicted data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "# plot the results\n",
    "X, Y = data.T[0], data.T[1]\n",
    "plt.plot(X, Y, 'bo', label='Real data')\n",
    "plt.plot(X, X * X * w_value + X*u_value + b_value, 'r', label='Predicted data')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
